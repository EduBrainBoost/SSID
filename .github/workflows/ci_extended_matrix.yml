name: CI Extended Matrix - v5.2 WORM + OPA + WASM

on:
  push:
    branches: [main, dev, staging]
    paths:
      - '23_compliance/policies/**'
      - '07_governance_legal/docs/pricing/**'
      - '11_test_simulation/**'
      - '13_ui_layer/**'
      - '.github/workflows/ci_extended_matrix.yml'
  pull_request:
    branches: [main]
  workflow_dispatch:
    inputs:
      env_override:
        description: 'Environment override (dev/stage/prod)'
        required: false
        default: 'dev'

env:
  NODE_VERSION: '20.x'
  PYTHON_VERSION: '3.11'
  OPA_VERSION: '0.60.0'
  AJV_CLI_VERSION: '5.0.0'

jobs:
  matrix-build:
    name: Build & Test (${{ matrix.env }})
    runs-on: ubuntu-latest
    strategy:
      matrix:
        env: [dev, stage, prod]
      fail-fast: false

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install OPA
        run: |
          curl -L -o opa https://openpolicyagent.org/downloads/v${{ env.OPA_VERSION }}/opa_linux_amd64_static
          chmod +x opa
          sudo mv opa /usr/local/bin/
          opa version

      - name: Install Python dependencies
        run: |
          pip install pytest pytest-json-report pyyaml

      - name: Install Node dependencies
        run: |
          npm ci
          npm install -g ajv-cli@${{ env.AJV_CLI_VERSION }}
          npm install -g yq

      - name: Install Playwright
        run: |
          npm install -D @playwright/test
          npx playwright install --with-deps chromium

      # STEP 1: Schema Validation (ajv)
      - name: Validate JSON Schemas
        id: schema_validate
        run: |
          echo "==> Validating Enterprise Subscription Schema"
          yq -o=json eval 07_governance_legal/docs/pricing/enterprise_subscription_model_v5_2.yaml 2>/dev/null \
            | ajv validate -s 05_documentation/schemas/enterprise_subscription_v5_2.schema.json -d /dev/stdin || true

          echo "==> Validating RAT Zone Schema"
          yq -o=json eval 07_governance_legal/docs/pricing/rat_zone_resolution_v5_2.yaml 2>/dev/null \
            | ajv validate -s 05_documentation/schemas/rat_zone_v5_2.schema.json -d /dev/stdin || true

          echo "==> Validating SLA Set Schema"
          yq -o=json eval 07_governance_legal/docs/slas/sla_set_v5_2.yaml 2>/dev/null \
            | ajv validate -s 05_documentation/schemas/sla_set_v5_2.schema.json -d /dev/stdin || true

      # STEP 2: OPA WASM Build
      - name: Build OPA WASM Bundles
        id: wasm_build
        run: |
          mkdir -p 02_audit_logging/logs

          echo "==> Building Pricing WASM"
          if [ -f "23_compliance/policies/pricing_enforcement_v5_2.rego" ]; then
            opa build -t wasm -e ssid/pricing/v5_2/allow \
              23_compliance/policies/pricing_enforcement_v5_2.rego \
              -o pricing_v5_2.tar.gz
            tar -xzf pricing_v5_2.tar.gz
            sha256sum policy.wasm | awk '{print $1}' >> 02_audit_logging/logs/opa_wasm_sha256.txt
            mv policy.wasm pricing_v5_2.wasm
          fi

          echo "==> Building RAT WASM"
          if [ -f "23_compliance/policies/rat_enforcement_v5_2.rego" ]; then
            opa build -t wasm -e ssid/rat/enforcement/v5_2/valid \
              23_compliance/policies/rat_enforcement_v5_2.rego \
              -o rat_v5_2.tar.gz
            tar -xzf rat_v5_2.tar.gz
            sha256sum policy.wasm | awk '{print $1}' >> 02_audit_logging/logs/opa_wasm_sha256.txt
            mv policy.wasm rat_v5_2.wasm
          fi

          echo "==> WASM SHA-256 Hashes:"
          cat 02_audit_logging/logs/opa_wasm_sha256.txt || true

      # STEP 3: Pytest
      - name: Run Pytest
        id: pytest
        continue-on-error: true
        run: |
          if [ -f "11_test_simulation/tests/test_pricing_v5_2.py" ]; then
            pytest 11_test_simulation/tests/test_pricing_v5_2.py -v --json-report --json-report-file=pytest_report.json
          fi

      # STEP 4: OPA Regression Runner (25 fixtures)
      - name: Run OPA Regression Matrix
        id: opa_regression
        continue-on-error: true
        run: |
          if [ -f "11_test_simulation/tools/opa_regression_runner.py" ]; then
            python 11_test_simulation/tools/opa_regression_runner.py \
              --env ${{ matrix.env }} \
              --out 02_audit_logging/reports/opa_regression_matrix_v5_2_${{ matrix.env }}.json
          fi

      # STEP 5: Playwright WASM Gate
      - name: Run Playwright WASM Gate Tests
        id: playwright
        continue-on-error: true
        run: |
          if [ -f "13_ui_layer/tests/playwright_wasm.spec.ts" ]; then
            npx playwright test 13_ui_layer/tests/playwright_wasm.spec.ts \
              --reporter=json \
              --output=13_ui_layer/reports/playwright_proof_log_${{ matrix.env }}.json
          fi

      # STEP 6: Collect Artifact Hashes
      - name: Collect Artifact Integrity Hashes
        id: integrity
        run: |
          mkdir -p 02_audit_logging/logs
          echo "{}" > 02_audit_logging/logs/artifacts_sha256_${{ matrix.env }}.json

          # Collect all relevant file hashes
          find 23_compliance/policies -name "*.rego" -type f -exec sha256sum {} \; > /tmp/policy_hashes.txt
          find 07_governance_legal/docs/pricing -name "*.yaml" -type f -exec sha256sum {} \; > /tmp/pricing_hashes.txt
          find 05_documentation/schemas -name "*.json" -type f -exec sha256sum {} \; > /tmp/schema_hashes.txt

          # Convert to JSON
          python3 << 'EOF'
          import json
          import os

          hashes = {}
          for file in ['/tmp/policy_hashes.txt', '/tmp/pricing_hashes.txt', '/tmp/schema_hashes.txt']:
              if os.path.exists(file):
                  with open(file) as f:
                      for line in f:
                          parts = line.strip().split(maxsplit=1)
                          if len(parts) == 2:
                              hashes[parts[1]] = parts[0]

          with open('02_audit_logging/logs/artifacts_sha256_${{ matrix.env }}.json', 'w') as f:
              json.dump(hashes, f, indent=2, sort_keys=True)
          EOF

      # STEP 7: Generate WORM Manifest
      - name: Generate WORM Manifest
        id: worm
        run: |
          mkdir -p 02_audit_logging/worm

          if [ -f "02_audit_logging/tools/generate_worm_manifest.py" ]; then
            python 02_audit_logging/tools/generate_worm_manifest.py \
              --artifacts-list 02_audit_logging/logs/artifacts_sha256_${{ matrix.env }}.json \
              --opa-decisions 02_audit_logging/reports/opa_regression_matrix_v5_2_${{ matrix.env }}.json \
              --wasm-hash 02_audit_logging/logs/opa_wasm_sha256.txt \
              --env ${{ matrix.env }} \
              --out 02_audit_logging/worm/worm_manifest_${{ matrix.env }}.json \
              --append
          fi

      # STEP 8: Calculate Compliance Score
      - name: Calculate Compliance Score
        id: score
        run: |
          mkdir -p 23_compliance/reports

          python3 << 'EOF'
          import json
          import os

          score = {
              "version": "5.2",
              "environment": "${{ matrix.env }}",
              "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
              "schema_validation": "PASS" if "${{ steps.schema_validate.outcome }}" == "success" else "FAIL",
              "wasm_build": "PASS" if "${{ steps.wasm_build.outcome }}" == "success" else "FAIL",
              "pytest": "PASS" if "${{ steps.pytest.outcome }}" == "success" else "FAIL",
              "opa_regression": "PASS" if "${{ steps.opa_regression.outcome }}" == "success" else "FAIL",
              "playwright": "PASS" if "${{ steps.playwright.outcome }}" == "success" else "FAIL",
              "worm_manifest": "PASS" if "${{ steps.worm.outcome }}" == "success" else "FAIL",
          }

          passed = sum(1 for v in score.values() if v == "PASS")
          total = len([k for k in score.keys() if k not in ["version", "environment", "timestamp"]])

          score["composite_score"] = round((passed / total) * 100, 2) if total > 0 else 0
          score["state"] = "PASS" if score["composite_score"] == 100 else "PARTIAL"
          score["epistemic_certainty"] = 1.0 if score["composite_score"] == 100 else round(passed / total, 2)

          with open('23_compliance/reports/ci_extended_matrix_score_${{ matrix.env }}.json', 'w') as f:
              json.dump(score, f, indent=2, sort_keys=True)

          print(f"Composite Score: {score['composite_score']}/100")
          EOF

      # STEP 9: Upload Artifacts
      - name: Upload CI Artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: ci-extended-matrix-${{ matrix.env }}
          path: |
            02_audit_logging/reports/opa_regression_matrix_v5_2_${{ matrix.env }}.json
            02_audit_logging/logs/artifacts_sha256_${{ matrix.env }}.json
            02_audit_logging/logs/opa_wasm_sha256.txt
            02_audit_logging/worm/worm_manifest_${{ matrix.env }}.json
            23_compliance/reports/ci_extended_matrix_score_${{ matrix.env }}.json
            13_ui_layer/reports/playwright_proof_log_${{ matrix.env }}.json
            pricing_v5_2.wasm
            rat_v5_2.wasm
          retention-days: 90

      # STEP 10: Fail on Score < 100
      - name: Enforce 100/100 Score
        run: |
          SCORE=$(jq -r '.composite_score' 23_compliance/reports/ci_extended_matrix_score_${{ matrix.env }}.json)
          echo "Composite Score: $SCORE/100"

          if [ "$(echo "$SCORE < 100" | bc)" -eq 1 ]; then
            echo "❌ Composite score below 100/100 - CI FAILED"
            exit 1
          fi

          echo "✅ Composite score: 100/100 - CI PASSED"

  consolidate:
    name: Consolidate Matrix Results
    needs: matrix-build
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/

      - name: Consolidate scores
        run: |
          mkdir -p 02_audit_logging/reports

          python3 << 'EOF'
          import json
          import os
          from pathlib import Path

          scores = []
          for env in ['dev', 'stage', 'prod']:
              score_file = Path(f'artifacts/ci-extended-matrix-{env}/23_compliance/reports/ci_extended_matrix_score_{env}.json')
              if score_file.exists():
                  with open(score_file) as f:
                      scores.append(json.load(f))

          consolidated = {
              "version": "5.2",
              "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
              "environments": scores,
              "overall_pass": all(s.get('composite_score', 0) == 100 for s in scores),
              "min_score": min((s.get('composite_score', 0) for s in scores), default=0),
              "max_score": max((s.get('composite_score', 0) for s in scores), default=0),
              "avg_score": round(sum(s.get('composite_score', 0) for s in scores) / len(scores), 2) if scores else 0
          }

          with open('02_audit_logging/reports/ci_extended_matrix_consolidated.json', 'w') as f:
              json.dump(consolidated, f, indent=2, sort_keys=True)

          print(f"Overall Pass: {consolidated['overall_pass']}")
          print(f"Min Score: {consolidated['min_score']}/100")
          print(f"Max Score: {consolidated['max_score']}/100")
          print(f"Avg Score: {consolidated['avg_score']}/100")
          EOF

      - name: Upload consolidated report
        uses: actions/upload-artifact@v4
        with:
          name: ci-extended-matrix-consolidated
          path: 02_audit_logging/reports/ci_extended_matrix_consolidated.json
          retention-days: 90
