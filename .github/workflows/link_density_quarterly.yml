name: Link Density Quarterly Analysis

on:
  schedule:
    # Run quarterly: 1st day of Jan/Apr/Jul/Oct at 00:00 UTC
    - cron: '0 0 1 1,4,7,10 *'
  workflow_dispatch:  # Allow manual trigger

jobs:
  link-density-analysis:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pyyaml

      - name: Generate dependency graph
        run: |
          python 02_audit_logging/anti_gaming/dependency_graph_generator.py

      - name: Run link density analysis
        id: analysis
        run: |
          python 12_tooling/quality/link_density_analyzer.py
          echo "analysis_complete=true" >> $GITHUB_OUTPUT

      - name: Check consolidation status
        id: consolidation
        run: |
          # Check if ShardHealthCheck base class exists
          if [ -f "03_core/healthcheck/shard_health_base.py" ]; then
            echo "base_class_exists=true" >> $GITHUB_OUTPUT

            # Count shard health subclasses
            subclass_count=$(find . -path "*/shards/*/health.py" | wc -l)
            echo "subclass_count=$subclass_count" >> $GITHUB_OUTPUT

            echo "âœ… ShardHealthCheck base class found"
            echo "ðŸ“Š Shard subclasses: $subclass_count"
          else
            echo "base_class_exists=false" >> $GITHUB_OUTPUT
            echo "âš ï¸  ShardHealthCheck base class not found"
          fi

      - name: Install OPA
        run: |
          curl -L -o opa https://openpolicyagent.org/downloads/latest/opa_linux_amd64
          chmod +x opa
          sudo mv opa /usr/local/bin/

      - name: Prepare OPA input with consolidation status
        run: |
          # Get latest analysis report
          REPORT=$(ls -t 12_tooling/quality/reports/link_density_analysis_*.json | head -1)

          # Add consolidation status to analysis
          python -c "
          import json
          import sys

          with open('$REPORT', 'r') as f:
              data = json.load(f)

          # Add consolidation status
          data['consolidation_status'] = {
              'base_class_exists': '${{ steps.consolidation.outputs.base_class_exists }}' == 'true',
              'subclass_count': int('${{ steps.consolidation.outputs.subclass_count }}' or 0)
          }

          with open('link_density_input.json', 'w') as f:
              json.dump(data, f, indent=2)
          "

      - name: Evaluate OPA policy
        id: opa
        run: |
          opa eval -d 23_compliance/policies/opa/link_density_threshold.rego \
                   -i link_density_input.json \
                   --format pretty \
                   "data.ecology.policy_decision" > opa_result.txt

          cat opa_result.txt

          # Check if policy allows
          if grep -q '"allow": true' opa_result.txt; then
            echo "âœ… OPA Policy: ALLOW"
            echo "opa_decision=allow" >> $GITHUB_OUTPUT
          else
            echo "âŒ OPA Policy: DENY"
            echo "opa_decision=deny" >> $GITHUB_OUTPUT
          fi

      - name: Generate YAML vital signs
        id: vital_signs
        run: |
          QUARTER=$(date +%Y-Q$(($(date +%-m-1)/3+1)))

          echo "Generating YAML Vital Signs for $QUARTER..."
          python 12_tooling/quality/yaml_vital_signs_generator.py --quarter "$QUARTER"

          echo "vital_signs_generated=true" >> $GITHUB_OUTPUT

      - name: Generate quarterly report
        run: |
          QUARTER=$(date +%Y-Q$(($(date +%-m-1)/3+1)))

          python -c "
          import json
          from datetime import datetime, timezone
          from pathlib import Path

          # Load analysis
          import glob
          report_files = sorted(glob.glob('12_tooling/quality/reports/link_density_analysis_*.json'))
          with open(report_files[-1], 'r') as f:
              analysis = json.load(f)

          # Load OPA result
          with open('opa_result.txt', 'r') as f:
              opa_result = f.read()

          # Load vital signs
          vital_signs_file = Path('12_tooling/quality/vital_signs') / f\"yaml_vital_signs_{QUARTER.replace('-', '_')}.json\"
          vital_signs = {}
          if vital_signs_file.exists():
              with open(vital_signs_file, 'r') as f:
                  vital_signs = json.load(f)

          # Generate quarterly report
          report = {
              'quarter': '$QUARTER',
              'generated_at': datetime.now(timezone.utc).isoformat(),
              'analysis_summary': analysis['graph_metrics'],
              'efficiency_assessment': analysis['efficiency_assessment'],
              'deduplication_recommendations': len(analysis['deduplication_recommendations']),
              'opa_decision': '${{ steps.opa.outputs.opa_decision }}',
              'consolidation_status': {
                  'base_class_exists': '${{ steps.consolidation.outputs.base_class_exists }}' == 'true',
                  'subclass_count': int('${{ steps.consolidation.outputs.subclass_count }}' or 0)
              },
              'vital_signs': vital_signs.get('vital_signs', {}),
              'overall_health': vital_signs.get('overall_health', 'UNKNOWN'),
              'status': 'PASS' if '${{ steps.opa.outputs.opa_decision }}' == 'allow' else 'FAIL'
          }

          with open('quarterly_report_$QUARTER.json', 'w') as f:
              json.dump(report, f, indent=2)

          print('Quarterly Report Generated: quarterly_report_$QUARTER.json')
          " QUARTER=$QUARTER

      - name: Upload reports as artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: link-density-quarterly-reports
          path: |
            12_tooling/quality/reports/link_density_analysis_*.json
            12_tooling/quality/vital_signs/yaml_vital_signs_*.json
            12_tooling/quality/vital_signs/yaml_vital_signs_*.md
            quarterly_report_*.json
            link_density_input.json
            opa_result.txt
          retention-days: 365

      - name: Create GitHub issue if action required
        if: steps.opa.outputs.opa_decision == 'deny'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const report = JSON.parse(fs.readFileSync('quarterly_report_' + process.env.QUARTER + '.json', 'utf8'));

            const issue = {
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `[Quarterly] Link Density Analysis - Action Required (${process.env.QUARTER})`,
              body: `## Link Density Analysis - ${process.env.QUARTER}

            **Status**: âš ï¸ ACTION REQUIRED

            ### Summary
            - **Link Density**: ${report.analysis_summary.link_density}
            - **Isolation Rate**: ${report.analysis_summary.isolation_rate}
            - **OPA Decision**: ${report.opa_decision}

            ### Consolidation Status
            - **Base Class Exists**: ${report.consolidation_status.base_class_exists ? 'âœ…' : 'âŒ'}
            - **Subclass Count**: ${report.consolidation_status.subclass_count}

            ### Recommendations
            ${report.deduplication_recommendations} optimization opportunities identified.

            ### Next Steps
            1. Review quarterly analysis report in workflow artifacts
            2. Implement HIGH priority recommendations
            3. Run consolidation script if needed:
               \`\`\`bash
               python 12_tooling/scripts/consolidate_shard_health_modules.py
               \`\`\`

            See workflow run: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
            `,
              labels: ['quarterly-review', 'optimization', 'link-density']
            };

            await github.rest.issues.create(issue);

      - name: Post summary
        if: always()
        run: |
          echo "## Link Density Quarterly Analysis" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Get quarter
          QUARTER=$(date +%Y-Q$(($(date +%-m-1)/3+1)))

          echo "### YAML Vital Signs - $QUARTER" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Read vital signs markdown and append to summary
          VITAL_SIGNS_MD="12_tooling/quality/vital_signs/yaml_vital_signs_${QUARTER//-/_}.md"
          if [ -f "$VITAL_SIGNS_MD" ]; then
            cat "$VITAL_SIGNS_MD" >> $GITHUB_STEP_SUMMARY
          else
            echo "Vital signs report not found" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Link Density Analysis" >> $GITHUB_STEP_SUMMARY

          python -c "
          import json
          import glob

          report_files = sorted(glob.glob('12_tooling/quality/reports/link_density_analysis_*.json'))
          with open(report_files[-1], 'r') as f:
              analysis = json.load(f)

          print('**Link Density**: ' + analysis['graph_metrics']['link_density'])
          print('**Isolation Rate**: ' + analysis['graph_metrics']['isolation_rate'])
          print('**Low Connectivity**: ' + analysis['connectivity_analysis']['low_connectivity_percentage'])
          print()
          print('### OPA Policy Decision')
          print('**Decision**: ${{ steps.opa.outputs.opa_decision }}'.upper())
          print()
          print('### Consolidation Status')
          print('- Base Class: ${{ steps.consolidation.outputs.base_class_exists }}' == 'true' and 'âœ… Exists' or 'âŒ Not Found')
          print('- Subclasses: ${{ steps.consolidation.outputs.subclass_count }}')
          " >> $GITHUB_STEP_SUMMARY
