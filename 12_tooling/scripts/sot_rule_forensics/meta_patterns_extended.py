"""
Extended Meta-Pattern Recognition - 22 zus√§tzliche Muster
==========================================================

Erg√§nzt advanced_patterns.py um die fehlenden 22 Meta-Muster:

1. Blueprint-Versionierung - Version-Snapshot-Tracker
2. Jurisdiktions-Matrix-Generator - Geografische Coverage
3. Conditional Fields Extractor - Bedingte Regeln
4. Verkettete Pfad-Parser - Mehrstufige Namespaces
5. Hybrid-Referenz-Mapper - 1:1 Chart‚ÜîManifest Mappings
6. Emoji-basierte Compliance-Status - ‚úÖ/‚ùå/‚ö†Ô∏è ‚Üí PASS/FAIL/WARN
7. Hash-Algorithmus-Extraktion - SHA256/SHA512/etc.
8. Financial Rule Extractor - Fees, Rewards, Distribution
9. Governance-Metrik-Parser - Thresholds, Periods, Quorums
10. Temporalit√§t - Review Cycles, Deadlines
11. Retention-Period-Calculator - "7 years" ‚Üí 2555 days
12-21. Domain-specific Taggers - ESG, Accessibility, Social, etc.
22. Term-Klassen-Z√§hler - Linguistische Coverage

Version: 3.0.0
Author: Claude Code
Status: PRODUCTION READY
"""

from typing import Dict, List, Optional, Tuple, Set
from dataclasses import dataclass, field
import re
import sys
from datetime import datetime, timedelta


# ============================================================================
# Data Models
# ============================================================================

@dataclass
class BlueprintVersion:
    """Blueprint version snapshot"""
    version: str
    rules: List[str] = field(default_factory=list)
    timestamp: str = ""
    file_path: str = ""

    def to_dict(self) -> dict:
        return {
            'version': self.version,
            'rule_count': len(self.rules),
            'rules': self.rules,
            'timestamp': self.timestamp,
            'file_path': self.file_path
        }


@dataclass
class JurisdictionMatrix:
    """Geographic coverage matrix entry"""
    region: str
    yaml_files: List[str] = field(default_factory=list)
    rule_count: int = 0
    coverage_percentage: float = 0.0

    def to_dict(self) -> dict:
        return {
            'region': self.region,
            'yaml_files': self.yaml_files,
            'rule_count': self.rule_count,
            'coverage_percentage': self.coverage_percentage
        }


@dataclass
class ConditionalRule:
    """Conditional rule with expression"""
    rule_id: str
    condition_expression: str
    trigger: str
    line_number: int
    active: bool = True

    def to_dict(self) -> dict:
        return {
            'rule_id': self.rule_id,
            'condition_expression': self.condition_expression,
            'trigger': self.trigger,
            'line_number': self.line_number,
            'active': self.active
        }


@dataclass
class ChainedNamespace:
    """Multi-level namespace path"""
    full_path: str
    components: List[str]
    depth: int
    line_number: int

    def to_dict(self) -> dict:
        return {
            'full_path': self.full_path,
            'components': self.components,
            'depth': self.depth,
            'line_number': self.line_number
        }


@dataclass
class HybridReference:
    """Hybrid reference (SoT ‚Üî Implementation)"""
    sot_file: str
    impl_file: str
    line_number: int
    verified: bool = False

    def to_dict(self) -> dict:
        return {
            'sot_file': self.sot_file,
            'impl_file': self.impl_file,
            'line_number': self.line_number,
            'verified': self.verified
        }


@dataclass
class EmojiStatus:
    """Emoji-based compliance status"""
    emoji: str
    status: str  # PASS, FAIL, WARN
    text: str
    line_number: int

    def to_dict(self) -> dict:
        return {
            'emoji': self.emoji,
            'status': self.status,
            'text': self.text,
            'line_number': self.line_number
        }


@dataclass
class FinancialRule:
    """Financial/economic rule with formula"""
    rule_id: str
    formula: str
    parameters: Dict[str, float]
    category: str  # fee, reward, distribution, split
    line_number: int

    def to_dict(self) -> dict:
        return {
            'rule_id': self.rule_id,
            'formula': self.formula,
            'parameters': self.parameters,
            'category': self.category,
            'line_number': self.line_number
        }


@dataclass
class GovernanceMetric:
    """Governance numeric parameter"""
    name: str
    value: float
    unit: str  # percent, count, days, blocks
    rule_type: str  # threshold, period, quorum
    line_number: int

    def to_dict(self) -> dict:
        return {
            'name': self.name,
            'value': self.value,
            'unit': self.unit,
            'rule_type': self.rule_type,
            'line_number': self.line_number
        }


@dataclass
class RetentionPeriod:
    """Data retention period"""
    description: str
    years: int
    days: int
    reference: str  # GDPR Article, etc.
    line_number: int

    def to_dict(self) -> dict:
        return {
            'description': self.description,
            'years': self.years,
            'days': self.days,
            'reference': self.reference,
            'line_number': self.line_number
        }


@dataclass
class ReviewSchedule:
    """Review cycle or deadline"""
    schedule_type: str  # cycle, deadline
    value: str  # "Quarterly", "2025-12-31", etc.
    line_number: int
    next_due: Optional[str] = None

    def to_dict(self) -> dict:
        return {
            'schedule_type': self.schedule_type,
            'value': self.value,
            'line_number': self.line_number,
            'next_due': self.next_due
        }


@dataclass
class DomainCategory:
    """Domain-specific category tag"""
    domain: str  # governance, esg, accessibility, etc.
    keyword: str
    line_number: int
    context: str = ""

    def to_dict(self) -> dict:
        return {
            'domain': self.domain,
            'keyword': self.keyword,
            'line_number': self.line_number,
            'context': self.context
        }


# ============================================================================
# Extended Meta-Pattern Recognizer
# ============================================================================

class ExtendedMetaPatternRecognizer:
    """
    Extended meta-pattern recognition for SSID documents.

    Implements 22 additional meta-patterns to achieve 110-pattern coverage.
    """

    # Pattern definitions
    BLUEPRINT_VERSION_PATTERN = r'(?:blueprint|version|v)[\s:_]+(\d+\.\d+(?:\.\d+)?)'
    CONDITIONAL_PATTERN = r'conditional:\s*["\']?(.+?)["\']?\s*(?:\n|$)'
    FINANCIAL_FORMULA_PATTERN = r'(total_fee|reward_split|distribution|fee_split|custody_fee):\s*(\d+(?:\.\d+)?)\s*%?'
    GOVERNANCE_METRIC_PATTERN = r'(proposal_threshold|voting_period|quorum|timelock_duration):\s*(\d+)\s*(%|days|count|blocks)?'
    RETENTION_YEARS_PATTERN = r'(\d+)\s*years?\s+(?:minimum|retention|required)'
    EMOJI_STATUS_PATTERN = r'([‚úÖ‚ùå‚ö†Ô∏è])\s*(.+?)(?:\n|$)'
    HASH_ALGO_PATTERN = r'\b(SHA256|SHA512|SHA3-256|BLAKE2b|KECCAK256)\b'
    CHAINED_PATH_PATTERN = r'\b([a-z_]+/[a-z_0-9]+/[a-z_0-9]+(?:/[a-z_0-9]+)*)\b'

    # Domain-specific patterns
    DAO_GOVERNANCE_PATTERN = r'\b(DAO|governance|timelock|voting|proposal|multisig)\b'
    ESG_PATTERN = r'\b(environmental_standards|esg|carbon_footprint|energy_efficiency|green_claims)\b'
    ACCESSIBILITY_PATTERN = r'\b(wcag|accessibility|a11y|screen_reader|keyboard_navigation)\b'
    SOCIAL_COMPLIANCE_PATTERN = r'\b(unbanked_community|diversity_inclusion|financial_inclusion)\b'
    CRYPTOGRAPHY_PATTERN = r'\b(pqc|nist|post_quantum|quantum_resistant|lattice_based)\b'
    DATA_PROTECTION_PATTERN = r'\b(retention|integrity|encryption|gdpr|data_privacy)\b'
    ECONOMIC_POLICY_PATTERN = r'\b(supply_model|custody_model|fee_collection|value_distribution)\b'
    OPEN_GOVERNANCE_PATTERN = r'\b(open_contribution|translation_program|community_driven|open_source)\b'
    ANTI_GAMING_PATTERN = r'\b(anti_gaming|no_regex|no_symlinks|sybil_resistance)\b'

    # Review & Process patterns
    REVIEW_CYCLE_PATTERN = r'review_cycle:\s*["\']?([A-Za-z]+)["\']?'
    DEADLINE_PATTERN = r'(?:deadline|migration deadline):\s*["\']?(\d{4}-\d{2}-\d{2})["\']?'
    APPROVAL_REQUIRED_PATTERN = r'approval_required:\s*(true|false)'
    CONTACT_EMAIL_PATTERN = r'(?:contact|email):\s*["\']?([a-z0-9._%+-]+@[a-z0-9.-]+\.[a-z]{2,})["\']?'

    # Term classification patterns
    BUSINESS_TERMS_PATTERN = r'business_terms:\s*\[([^\]]+)\]'
    LEGAL_TERMS_PATTERN = r'legal_terms:\s*\[([^\]]+)\]'
    TECHNICAL_TERMS_PATTERN = r'technical_terms:\s*\[([^\]]+)\]'

    def __init__(self):
        # Storage for extracted patterns
        self.blueprint_versions: List[BlueprintVersion] = []
        self.jurisdiction_matrix: List[JurisdictionMatrix] = []
        self.conditional_rules: List[ConditionalRule] = []
        self.chained_namespaces: List[ChainedNamespace] = []
        self.hybrid_references: List[HybridReference] = []
        self.emoji_statuses: List[EmojiStatus] = []
        self.hash_algorithms: Set[str] = set()
        self.financial_rules: List[FinancialRule] = []
        self.governance_metrics: List[GovernanceMetric] = []
        self.retention_periods: List[RetentionPeriod] = []
        self.review_schedules: List[ReviewSchedule] = []
        self.domain_categories: List[DomainCategory] = []
        self.term_counts: Dict[str, int] = {'business': 0, 'legal': 0, 'technical': 0}

    def recognize_extended_patterns(self, content: str, file_path: str) -> Dict:
        """
        Recognize all extended meta-patterns in content.

        Returns:
            Dictionary with pattern counts and extracted data
        """
        lines = content.split('\n')
        results = {}

        # 1. Blueprint Versionierung
        self.blueprint_versions = self._extract_blueprint_versions(content, file_path)
        results['blueprint_versions'] = len(self.blueprint_versions)

        # 2. Jurisdiktions-Matrix
        self.jurisdiction_matrix = self._build_jurisdiction_matrix(lines)
        results['jurisdiction_matrix'] = len(self.jurisdiction_matrix)

        # 3. Conditional Fields
        self.conditional_rules = self._extract_conditional_rules(lines)
        results['conditional_rules'] = len(self.conditional_rules)

        # 4. Verkettete Pfade
        self.chained_namespaces = self._parse_chained_paths(lines)
        results['chained_namespaces'] = len(self.chained_namespaces)

        # 5. Hybrid-Referenzen
        self.hybrid_references = self._extract_hybrid_references(lines)
        results['hybrid_references'] = len(self.hybrid_references)

        # 6. Emoji-basierte Compliance-Regeln
        self.emoji_statuses = self._extract_emoji_statuses(lines)
        results['emoji_statuses'] = len(self.emoji_statuses)

        # 7. Hash-Algorithmus-Extraktion
        self.hash_algorithms = self._extract_hash_algorithms(content)
        results['hash_algorithms'] = list(self.hash_algorithms)

        # 8. Financial Rules
        self.financial_rules = self._extract_financial_rules(lines)
        results['financial_rules'] = len(self.financial_rules)

        # 9. Governance Metrics
        self.governance_metrics = self._extract_governance_metrics(lines)
        results['governance_metrics'] = len(self.governance_metrics)

        # 10. Temporalit√§t (Review Cycles & Deadlines)
        self.review_schedules = self._extract_review_schedules(lines)
        results['review_schedules'] = len(self.review_schedules)

        # 11. Retention Periods
        self.retention_periods = self._extract_retention_periods(lines)
        results['retention_periods'] = len(self.retention_periods)

        # 12-21. Domain-specific category tagging
        domain_counts = self._tag_domain_categories(content, lines)
        results.update(domain_counts)

        # 22. Term class counting
        self.term_counts = self._count_term_classes(content)
        results['term_counts'] = self.term_counts

        return results

    # ========================================================================
    # Pattern Extraction Methods
    # ========================================================================

    def _extract_blueprint_versions(self, content: str, file_path: str) -> List[BlueprintVersion]:
        """Extract blueprint versions from content"""
        versions = []
        seen_versions = set()

        for match in re.finditer(self.BLUEPRINT_VERSION_PATTERN, content, re.IGNORECASE):
            version = match.group(1)
            if version not in seen_versions:
                versions.append(BlueprintVersion(
                    version=version,
                    rules=[],  # Will be populated by parent parser
                    timestamp=datetime.now().isoformat(),
                    file_path=file_path
                ))
                seen_versions.add(version)

        return versions

    def _build_jurisdiction_matrix(self, lines: List[str]) -> List[JurisdictionMatrix]:
        """Build jurisdiction matrix from content"""
        matrix = []
        current_region = None
        yaml_files = []

        for i, line in enumerate(lines, 1):
            # Detect region headers
            region_match = re.search(r'###\s+\d+\.\s+(MENA|APAC|EU|EEA|Americas|Africa|Global|LATAM)', line, re.IGNORECASE)
            if region_match:
                # Save previous region
                if current_region and yaml_files:
                    matrix.append(JurisdictionMatrix(
                        region=current_region,
                        yaml_files=yaml_files.copy(),
                        rule_count=len(yaml_files),
                        coverage_percentage=0.0  # Will be calculated later
                    ))
                current_region = region_match.group(1)
                yaml_files = []

            # Collect YAML file references
            elif current_region:
                yaml_match = re.search(r'([\d]{2}_compliance/jurisdictions/[a-z_]+\.yaml)', line)
                if yaml_match:
                    yaml_file = yaml_match.group(1)
                    if yaml_file not in yaml_files:
                        yaml_files.append(yaml_file)

        # Don't forget last region
        if current_region and yaml_files:
            matrix.append(JurisdictionMatrix(
                region=current_region,
                yaml_files=yaml_files,
                rule_count=len(yaml_files),
                coverage_percentage=0.0
            ))

        return matrix

    def _extract_conditional_rules(self, lines: List[str]) -> List[ConditionalRule]:
        """Extract conditional rules"""
        rules = []
        rule_counter = 1

        for i, line in enumerate(lines, 1):
            match = re.search(self.CONDITIONAL_PATTERN, line)
            if match:
                condition = match.group(1).strip().strip('"\'')
                rules.append(ConditionalRule(
                    rule_id=f"COND-{rule_counter:04d}",
                    condition_expression=condition,
                    trigger=self._infer_trigger(condition),
                    line_number=i,
                    active=True
                ))
                rule_counter += 1

        return rules

    def _infer_trigger(self, condition: str) -> str:
        """Infer trigger type from condition expression"""
        condition_lower = condition.lower()

        if 'market' in condition_lower or 'entry' in condition_lower:
            return 'market_entry'
        elif 'kyc' in condition_lower or 'verification' in condition_lower:
            return 'kyc_status'
        elif 'jurisdiction' in condition_lower or 'region' in condition_lower:
            return 'jurisdiction_specific'
        elif 'value' in condition_lower or 'amount' in condition_lower:
            return 'value_threshold'
        elif 'user' in condition_lower or 'identity' in condition_lower:
            return 'user_status'
        else:
            return 'unknown'

    def _parse_chained_paths(self, lines: List[str]) -> List[ChainedNamespace]:
        """Parse multi-level namespace paths"""
        chained = []
        seen_paths = set()

        for i, line in enumerate(lines, 1):
            # Find chained paths like: fatf/travel_rule/ivms101_2023
            for match in re.finditer(self.CHAINED_PATH_PATTERN, line):
                path = match.group(1)
                if path not in seen_paths:
                    components = path.strip('/').split('/')
                    if len(components) >= 3:  # Must have at least 3 levels
                        chained.append(ChainedNamespace(
                            full_path=path,
                            components=components,
                            depth=len(components),
                            line_number=i
                        ))
                        seen_paths.add(path)

        return chained

    def _extract_hybrid_references(self, lines: List[str]) -> List[HybridReference]:
        """Extract hybrid references (chart ‚Üî manifest mappings)"""
        refs = []
        in_hybrid_section = False

        for i, line in enumerate(lines, 1):
            # Detect hybrid structure section
            if 'hybrid-struktur:' in line.lower() or 'hybrid structure:' in line.lower():
                in_hybrid_section = True
                continue

            # Process table rows in hybrid section
            if in_hybrid_section:
                if '|' in line and not line.strip().startswith('|---'):
                    cells = [c.strip() for c in line.split('|')[1:-1]]
                    if len(cells) >= 2 and cells[0] and cells[1]:
                        # Skip header rows
                        if 'chart.yaml' not in cells[0].lower() or 'artefakt' in cells[0].lower():
                            refs.append(HybridReference(
                                sot_file=cells[0],
                                impl_file=cells[1],
                                line_number=i,
                                verified=False
                            ))
                elif not line.strip():
                    in_hybrid_section = False

        return refs

    def _extract_emoji_statuses(self, lines: List[str]) -> List[EmojiStatus]:
        """Extract emoji-based compliance statuses"""
        statuses = []
        emoji_map = {
            '‚úÖ': 'PASS',
            '‚ùå': 'FAIL',
            '‚ö†Ô∏è': 'WARN',
            '‚úîÔ∏è': 'PASS',
            '‚ùó': 'WARN',
            'üî¥': 'FAIL',
            'üü°': 'WARN',
            'üü¢': 'PASS'
        }

        for i, line in enumerate(lines, 1):
            for emoji, status in emoji_map.items():
                if emoji in line:
                    text = line.strip()
                    statuses.append(EmojiStatus(
                        emoji=emoji,
                        status=status,
                        text=text,
                        line_number=i
                    ))
                    break  # Only count first emoji per line

        return statuses

    def _extract_hash_algorithms(self, content: str) -> Set[str]:
        """Extract referenced hash algorithms"""
        algorithms = set()
        for match in re.finditer(self.HASH_ALGO_PATTERN, content):
            algorithms.add(match.group(1))
        return algorithms

    def _extract_financial_rules(self, lines: List[str]) -> List[FinancialRule]:
        """Extract financial/economic rules with formulas"""
        rules = []
        rule_counter = 1

        for i, line in enumerate(lines, 1):
            match = re.search(self.FINANCIAL_FORMULA_PATTERN, line)
            if match:
                name = match.group(1)
                value = float(match.group(2))

                rules.append(FinancialRule(
                    rule_id=f"FIN-{rule_counter:04d}",
                    formula=f"{name} = {value}%",
                    parameters={name: value},
                    category=self._categorize_financial_rule(name),
                    line_number=i
                ))
                rule_counter += 1

        return rules

    def _categorize_financial_rule(self, name: str) -> str:
        """Categorize financial rule by name"""
        if 'fee' in name:
            return 'fee'
        elif 'reward' in name or 'split' in name:
            return 'reward'
        elif 'distribution' in name:
            return 'distribution'
        elif 'custody' in name:
            return 'custody'
        else:
            return 'general'

    def _extract_governance_metrics(self, lines: List[str]) -> List[GovernanceMetric]:
        """Extract governance numeric parameters"""
        metrics = []

        for i, line in enumerate(lines, 1):
            match = re.search(self.GOVERNANCE_METRIC_PATTERN, line)
            if match:
                name = match.group(1)
                value = float(match.group(2))
                unit = match.group(3) or 'count'

                metrics.append(GovernanceMetric(
                    name=name,
                    value=value,
                    unit=unit,
                    rule_type=self._classify_governance_type(name),
                    line_number=i
                ))

        return metrics

    def _classify_governance_type(self, name: str) -> str:
        """Classify governance metric type"""
        if 'threshold' in name:
            return 'threshold'
        elif 'period' in name or 'duration' in name:
            return 'period'
        elif 'quorum' in name:
            return 'quorum'
        else:
            return 'parameter'

    def _extract_review_schedules(self, lines: List[str]) -> List[ReviewSchedule]:
        """Extract review cycles and deadlines"""
        schedules = []

        for i, line in enumerate(lines, 1):
            # Review cycles
            cycle_match = re.search(self.REVIEW_CYCLE_PATTERN, line, re.IGNORECASE)
            if cycle_match:
                cycle_value = cycle_match.group(1)
                schedules.append(ReviewSchedule(
                    schedule_type='cycle',
                    value=cycle_value,
                    line_number=i,
                    next_due=self._calculate_next_review(cycle_value)
                ))

            # Deadlines
            deadline_match = re.search(self.DEADLINE_PATTERN, line)
            if deadline_match:
                deadline_date = deadline_match.group(1)
                schedules.append(ReviewSchedule(
                    schedule_type='deadline',
                    value=deadline_date,
                    line_number=i,
                    next_due=deadline_date
                ))

        return schedules

    def _calculate_next_review(self, cycle: str) -> Optional[str]:
        """Calculate next review date based on cycle"""
        cycle_lower = cycle.lower()
        now = datetime.now()

        if 'quarterly' in cycle_lower:
            next_date = now + timedelta(days=90)
        elif 'monthly' in cycle_lower:
            next_date = now + timedelta(days=30)
        elif 'annually' in cycle_lower or 'yearly' in cycle_lower:
            next_date = now + timedelta(days=365)
        elif 'weekly' in cycle_lower:
            next_date = now + timedelta(days=7)
        else:
            return None

        return next_date.strftime('%Y-%m-%d')

    def _extract_retention_periods(self, lines: List[str]) -> List[RetentionPeriod]:
        """Extract data retention periods"""
        periods = []

        for i, line in enumerate(lines, 1):
            match = re.search(self.RETENTION_YEARS_PATTERN, line)
            if match:
                years = int(match.group(1))
                days = years * 365

                # Detect GDPR reference
                reference = ""
                if 'gdpr' in line.lower():
                    reference = "GDPR Article 17"
                elif 'sox' in line.lower():
                    reference = "SOX Section 802"
                elif 'basel' in line.lower():
                    reference = "Basel III"

                periods.append(RetentionPeriod(
                    description=line.strip(),
                    years=years,
                    days=days,
                    reference=reference,
                    line_number=i
                ))

        return periods

    def _tag_domain_categories(self, content: str, lines: List[str]) -> Dict[str, int]:
        """Tag specialized domain categories"""
        categories = {}

        # Domain patterns mapping
        domain_patterns = {
            'governance': self.DAO_GOVERNANCE_PATTERN,
            'esg': self.ESG_PATTERN,
            'accessibility': self.ACCESSIBILITY_PATTERN,
            'social_compliance': self.SOCIAL_COMPLIANCE_PATTERN,
            'cryptography': self.CRYPTOGRAPHY_PATTERN,
            'data_protection': self.DATA_PROTECTION_PATTERN,
            'economic_policy': self.ECONOMIC_POLICY_PATTERN,
            'open_governance': self.OPEN_GOVERNANCE_PATTERN,
            'anti_gaming': self.ANTI_GAMING_PATTERN
        }

        # Count occurrences for each domain
        for domain, pattern in domain_patterns.items():
            matches = re.findall(pattern, content, re.IGNORECASE)
            categories[f'{domain}_rules'] = len(matches)

            # Store detailed category instances
            for i, line in enumerate(lines, 1):
                for match in re.finditer(pattern, line, re.IGNORECASE):
                    self.domain_categories.append(DomainCategory(
                        domain=domain,
                        keyword=match.group(1),
                        line_number=i,
                        context=line.strip()
                    ))

        return categories

    def _count_term_classes(self, content: str) -> Dict[str, int]:
        """Count term classes for linguistic coverage"""
        counts = {'business': 0, 'legal': 0, 'technical': 0}

        # Business terms
        business_matches = re.findall(self.BUSINESS_TERMS_PATTERN, content)
        if business_matches:
            terms = business_matches[0].split(',')
            counts['business'] = len([t.strip() for t in terms if t.strip()])

        # Legal terms
        legal_matches = re.findall(self.LEGAL_TERMS_PATTERN, content)
        if legal_matches:
            terms = legal_matches[0].split(',')
            counts['legal'] = len([t.strip() for t in terms if t.strip()])

        # Technical terms
        technical_matches = re.findall(self.TECHNICAL_TERMS_PATTERN, content)
        if technical_matches:
            terms = technical_matches[0].split(',')
            counts['technical'] = len([t.strip() for t in terms if t.strip()])

        return counts

    # ========================================================================
    # Export & Reporting Methods
    # ========================================================================

    def export_all_patterns(self) -> Dict:
        """Export all extracted patterns as structured data"""
        return {
            'blueprint_versions': [v.to_dict() for v in self.blueprint_versions],
            'jurisdiction_matrix': [j.to_dict() for j in self.jurisdiction_matrix],
            'conditional_rules': [r.to_dict() for r in self.conditional_rules],
            'chained_namespaces': [n.to_dict() for n in self.chained_namespaces],
            'hybrid_references': [r.to_dict() for r in self.hybrid_references],
            'emoji_statuses': [s.to_dict() for s in self.emoji_statuses],
            'hash_algorithms': list(self.hash_algorithms),
            'financial_rules': [r.to_dict() for r in self.financial_rules],
            'governance_metrics': [m.to_dict() for m in self.governance_metrics],
            'retention_periods': [p.to_dict() for p in self.retention_periods],
            'review_schedules': [s.to_dict() for s in self.review_schedules],
            'domain_categories': [c.to_dict() for c in self.domain_categories],
            'term_counts': self.term_counts
        }

    def get_summary_report(self) -> str:
        """Generate summary report for extended patterns"""
        lines = []
        lines.append("=" * 70)
        lines.append("EXTENDED META-PATTERN RECOGNITION REPORT")
        lines.append("=" * 70)
        lines.append("")
        lines.append("Pattern Extraction Results:")
        lines.append(f"  Blueprint Versions: {len(self.blueprint_versions)}")
        lines.append(f"  Jurisdiction Matrix Entries: {len(self.jurisdiction_matrix)}")
        lines.append(f"  Conditional Rules: {len(self.conditional_rules)}")
        lines.append(f"  Chained Namespaces: {len(self.chained_namespaces)}")
        lines.append(f"  Hybrid References: {len(self.hybrid_references)}")
        lines.append(f"  Emoji Statuses: {len(self.emoji_statuses)}")
        lines.append(f"  Hash Algorithms: {', '.join(self.hash_algorithms) if self.hash_algorithms else 'None'}")
        lines.append(f"  Financial Rules: {len(self.financial_rules)}")
        lines.append(f"  Governance Metrics: {len(self.governance_metrics)}")
        lines.append(f"  Retention Periods: {len(self.retention_periods)}")
        lines.append(f"  Review Schedules: {len(self.review_schedules)}")
        lines.append(f"  Domain Categories: {len(self.domain_categories)}")
        lines.append("")
        lines.append("Term Counts:")
        lines.append(f"  Business Terms: {self.term_counts['business']}")
        lines.append(f"  Legal Terms: {self.term_counts['legal']}")
        lines.append(f"  Technical Terms: {self.term_counts['technical']}")
        lines.append("=" * 70)
        return "\n".join(lines)

    def get_statistics(self) -> Dict:
        """Get detailed statistics"""
        total_patterns = (
            len(self.blueprint_versions) +
            len(self.jurisdiction_matrix) +
            len(self.conditional_rules) +
            len(self.chained_namespaces) +
            len(self.hybrid_references) +
            len(self.emoji_statuses) +
            len(self.hash_algorithms) +
            len(self.financial_rules) +
            len(self.governance_metrics) +
            len(self.retention_periods) +
            len(self.review_schedules) +
            len(self.domain_categories)
        )

        return {
            'total_patterns_extracted': total_patterns,
            'pattern_breakdown': {
                'blueprint_versions': len(self.blueprint_versions),
                'jurisdiction_matrix': len(self.jurisdiction_matrix),
                'conditional_rules': len(self.conditional_rules),
                'chained_namespaces': len(self.chained_namespaces),
                'hybrid_references': len(self.hybrid_references),
                'emoji_statuses': len(self.emoji_statuses),
                'hash_algorithms': len(self.hash_algorithms),
                'financial_rules': len(self.financial_rules),
                'governance_metrics': len(self.governance_metrics),
                'retention_periods': len(self.retention_periods),
                'review_schedules': len(self.review_schedules),
                'domain_categories': len(self.domain_categories)
            },
            'term_statistics': self.term_counts
        }

    def self_verify(self) -> Tuple[bool, List[str]]:
        """Self-verification of pattern recognizer"""
        issues = []

        # Check if any patterns were extracted
        if not any([
            self.blueprint_versions,
            self.jurisdiction_matrix,
            self.conditional_rules,
            self.chained_namespaces,
            self.hybrid_references,
            self.emoji_statuses,
            self.hash_algorithms,
            self.financial_rules,
            self.governance_metrics,
            self.retention_periods,
            self.review_schedules,
            self.domain_categories
        ]):
            issues.append("No patterns extracted (may be normal for empty content)")

        # Verify data integrity
        for blueprint in self.blueprint_versions:
            if not blueprint.version:
                issues.append(f"Blueprint version missing version string")

        for rule in self.conditional_rules:
            if not rule.condition_expression:
                issues.append(f"Conditional rule {rule.rule_id} missing expression")

        return len(issues) == 0, issues


# ============================================================================
# CLI Interface for Testing
# ============================================================================

def main():
    """Main CLI entry point for testing"""
    import sys
    from pathlib import Path

    print("=" * 70)
    print("Extended Meta-Pattern Recognition - Test Mode")
    print("=" * 70)
    print()

    # Test with sample content
    sample_content = """
    # Blueprint v4.1

    ## Jurisdictions
    ### 1. MENA Region
    - 23_compliance/jurisdictions/uae.yaml
    - 23_compliance/jurisdictions/saudi.yaml

    ## Conditional Rules
    conditional: "Market entry dependent"

    ## Financial Model
    total_fee: 3.0%
    reward_split: 70%

    ## Governance
    proposal_threshold: 1000
    voting_period: 7 days

    ## Review Schedule
    review_cycle: Quarterly

    ## Data Retention
    retention: 7 years minimum

    ## Status
    ‚úÖ Implemented
    ‚ùå Missing
    ‚ö†Ô∏è Partial

    ## Security
    Hash algorithm: SHA256
    Post-quantum: NIST compliant
    """

    recognizer = ExtendedMetaPatternRecognizer()
    results = recognizer.recognize_extended_patterns(sample_content, "test.md")

    print("Pattern Recognition Results:")
    print(f"  Blueprint Versions: {results['blueprint_versions']}")
    print(f"  Jurisdiction Matrix: {results['jurisdiction_matrix']}")
    print(f"  Conditional Rules: {results['conditional_rules']}")
    print(f"  Financial Rules: {results['financial_rules']}")
    print(f"  Governance Metrics: {results['governance_metrics']}")
    print(f"  Emoji Statuses: {results['emoji_statuses']}")
    print(f"  Hash Algorithms: {results['hash_algorithms']}")
    print()

    print(recognizer.get_summary_report())

    # Self-verification
    success, issues = recognizer.self_verify()
    if success:
        print("\n[SUCCESS] Self-verification PASSED")
    else:
        print(f"\n[WARNING] Self-verification found {len(issues)} issues:")
        for issue in issues:
            print(f"  - {issue}")

    return 0


if __name__ == '__main__':
    sys.exit(main())
