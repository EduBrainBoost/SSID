#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
test_forensic_cleanup.py - Tests for Forensic Artifact Cleanup
Author: edubrainboost Â©2025 MIT License

Ensures forensic cleanup safety:
- Living code is NEVER touched
- Only temporary artifacts are deleted
- Archives are created before deletion
- SHA-256 verification succeeds
- Permanent evidence is preserved
"""

import sys
import json
import tempfile
import shutil
from pathlib import Path
from datetime import datetime, timezone, timedelta

# Add project root to path
project_root = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(project_root / "23_compliance" / "tools"))
sys.path.insert(0, str(project_root))

import pytest
from forensic_cleanup import ForensicCleanupManager


@pytest.fixture
def temp_repo():
    """Create temporary repository structure for testing."""
    with tempfile.TemporaryDirectory() as tmpdir:
        repo = Path(tmpdir)

        # Create directory structure
        (repo / "02_audit_logging" / "evidence").mkdir(parents=True)
        (repo / "02_audit_logging" / "archives" / "snapshots").mkdir(parents=True)
        (repo / "23_compliance" / "tools").mkdir(parents=True)
        (repo / "24_meta_orchestration" / "registry").mkdir(parents=True)

        # Create living code (should never be touched)
        living_code = repo / "core" / "policy.py"
        living_code.parent.mkdir(parents=True)
        living_code.write_text("# Living code - should never be deleted")

        # Create temporary artifacts (eligible for cleanup)
        old_report = repo / "02_audit_logging" / "evidence" / "test_report_20240101.json"
        old_report.write_text('{"test": "old report"}')

        # Set old timestamp (>30 days)
        old_time = (datetime.now() - timedelta(days=35)).timestamp()
        old_report.touch()
        import os
        os.utime(old_report, (old_time, old_time))

        # Create recent artifact (should NOT be cleaned)
        recent_report = repo / "02_audit_logging" / "evidence" / "test_report_20251010.json"
        recent_report.write_text('{"test": "recent report"}')

        # Create build artifact (safe to delete)
        build_artifact = repo / "__pycache__" / "test.pyc"
        build_artifact.parent.mkdir(parents=True)
        build_artifact.write_text("compiled")

        # Create policy file
        policy = repo / "24_meta_orchestration" / "registry" / "artifact_retention_policy.yaml"
        policy.write_text("""
version: 1
artifact_types:
  living_code:
    patterns: ["**/*.py"]
    exclusions: ["**/__pycache__/**"]
    retention: permanent
  generated_reports:
    patterns: ["**/*_report_*.json"]
    retention_days: 30
    archive_before_delete: true
  build_artifacts:
    patterns: ["**/__pycache__/**"]
    retention_days: 7
    archive_before_delete: false
exclusions:
  permanent: [".git/**"]
  directories: [".git"]
retention_strategy:
  mode: consolidate_then_archive
  consolidation:
    enabled: true
    output_directory: "02_audit_logging/archives/snapshots"
guardrails:
  verify_living_code_untouched: true
""")

        yield repo


def test_living_code_never_touched(temp_repo):
    """Test that living code is NEVER touched by cleanup."""
    manager = ForensicCleanupManager(
        root_dir=temp_repo,
        policy_path=temp_repo / "24_meta_orchestration" / "registry" / "artifact_retention_policy.yaml"
    )

    living_code_file = temp_repo / "core" / "policy.py"
    original_content = living_code_file.read_text()

    # Scan artifacts
    artifacts = manager.scan_artifacts()

    # Verify living code was classified
    assert any(f.name == "policy.py" for f in artifacts.get('living_code', []))

    # Get cleanup candidates
    candidates = manager.get_cleanup_candidates(artifacts)

    # Verify living code is NOT in cleanup candidates
    for artifact_type, files in candidates.items():
        assert not any(f.name == "policy.py" for f in files), \
            f"Living code found in cleanup candidates: {artifact_type}"

    # Verify file still exists and unchanged
    assert living_code_file.exists()
    assert living_code_file.read_text() == original_content


def test_temporary_artifacts_identified(temp_repo):
    """Test that temporary artifacts are correctly identified."""
    manager = ForensicCleanupManager(
        root_dir=temp_repo,
        policy_path=temp_repo / "24_meta_orchestration" / "registry" / "artifact_retention_policy.yaml"
    )

    artifacts = manager.scan_artifacts()

    # Should have classified generated reports
    assert 'generated_reports' in artifacts
    report_files = [f.name for f in artifacts['generated_reports']]
    assert any('test_report_' in name for name in report_files), \
        f"Expected test_report_ in {report_files}"

    # Should have classified build artifacts
    assert 'build_artifacts' in artifacts
    # Build artifact may be classified - check if any files present
    if artifacts['build_artifacts']:
        assert any('__pycache__' in str(f) or f.suffix == '.pyc' for f in artifacts['build_artifacts'])


def test_retention_window_enforced(temp_repo):
    """Test that retention windows are enforced correctly."""
    manager = ForensicCleanupManager(
        root_dir=temp_repo,
        policy_path=temp_repo / "24_meta_orchestration" / "registry" / "artifact_retention_policy.yaml"
    )

    artifacts = manager.scan_artifacts()
    candidates = manager.get_cleanup_candidates(artifacts)

    # Old report (>30 days) should be cleanup candidate
    old_report = temp_repo / "02_audit_logging" / "evidence" / "test_report_20240101.json"
    if 'generated_reports' in candidates:
        assert any(f.name == "test_report_20240101.json" for f in candidates['generated_reports']), \
            "Old report (>30 days) should be cleanup candidate"

    # Recent report (<30 days) should NOT be cleanup candidate
    if 'generated_reports' in candidates:
        assert not any(f.name == "test_report_20251010.json" for f in candidates['generated_reports']), \
            "Recent report (<30 days) should NOT be cleanup candidate"


def test_archive_before_delete(temp_repo):
    """Test that archives are created before deletion."""
    manager = ForensicCleanupManager(
        root_dir=temp_repo,
        policy_path=temp_repo / "24_meta_orchestration" / "registry" / "artifact_retention_policy.yaml"
    )

    # Create test report
    test_report = temp_repo / "02_audit_logging" / "evidence" / "archive_test_report_20240101.json"
    test_report.write_text('{"test": "data"}')

    # Consolidate reports
    snapshot_path, verification = manager.consolidate_reports(
        [test_report],
        "TEST_SNAPSHOT"
    )

    # Verify snapshot created
    assert snapshot_path.exists()
    assert snapshot_path.suffix == ".gz"

    # Verify verification file created
    verify_file = snapshot_path.with_suffix('.tar.gz.verify.json')
    assert verify_file.exists()

    # Verify checksum in verification file
    with open(verify_file, 'r') as f:
        verification_data = json.load(f)

    assert 'snapshot_sha256' in verification_data
    assert 'file_checksums' in verification_data
    assert verification_data['immutable'] is True


def test_permanent_evidence_preserved(temp_repo):
    """Test that permanent evidence patterns are preserved."""
    manager = ForensicCleanupManager(
        root_dir=temp_repo,
        policy_path=temp_repo / "24_meta_orchestration" / "registry" / "artifact_retention_policy.yaml"
    )

    # Create forensic manifest (permanent)
    forensic_manifest = temp_repo / "02_audit_logging" / "forensic_manifest.yaml"
    forensic_manifest.write_text("# Permanent forensic evidence")

    # Update policy to include forensic manifests as permanent
    policy_file = temp_repo / "24_meta_orchestration" / "registry" / "artifact_retention_policy.yaml"
    policy_content = policy_file.read_text()
    policy_content += """
  permanent_exclusions: ["**/forensic_manifest*.yaml"]
"""
    policy_file.write_text(policy_content)

    artifacts = manager.scan_artifacts()
    candidates = manager.get_cleanup_candidates(artifacts)

    # Verify forensic manifest is NOT in any cleanup candidates
    for artifact_type, files in candidates.items():
        assert not any(f.name == "forensic_manifest.yaml" for f in files), \
            f"Permanent evidence found in cleanup candidates: {artifact_type}"


def test_dry_run_safety(temp_repo):
    """Test that dry-run mode doesn't modify anything."""
    manager = ForensicCleanupManager(
        root_dir=temp_repo,
        policy_path=temp_repo / "24_meta_orchestration" / "registry" / "artifact_retention_policy.yaml"
    )

    # Record initial state
    all_files_before = {f for f in temp_repo.rglob("*") if f.is_file()}

    # Run cleanup in dry-run mode
    manager.cleanup_artifacts(dry_run=True)

    # Verify no files were deleted
    all_files_after = {f for f in temp_repo.rglob("*") if f.is_file()}
    assert all_files_before == all_files_after, "Dry-run mode modified files!"


def test_classification_accuracy(temp_repo):
    """Test that artifact classification is accurate."""
    manager = ForensicCleanupManager(
        root_dir=temp_repo,
        policy_path=temp_repo / "24_meta_orchestration" / "registry" / "artifact_retention_policy.yaml"
    )

    # Test living code classification
    living_code = temp_repo / "core" / "policy.py"
    assert manager.classify_file(living_code) == "living_code"

    # Test generated report classification
    report = temp_repo / "02_audit_logging" / "evidence" / "test_report_20240101.json"
    assert manager.classify_file(report) == "generated_reports"

    # Test build artifact classification
    build_file = temp_repo / "__pycache__" / "test.pyc"
    assert manager.classify_file(build_file) == "build_artifacts"


def test_file_age_calculation(temp_repo):
    """Test that file age is calculated correctly."""
    manager = ForensicCleanupManager(
        root_dir=temp_repo,
        policy_path=temp_repo / "24_meta_orchestration" / "registry" / "artifact_retention_policy.yaml"
    )

    # Create file with specific age
    test_file = temp_repo / "test_age.txt"
    test_file.write_text("test")

    # Set timestamp to 35 days ago
    old_time = (datetime.now() - timedelta(days=35)).timestamp()
    import os
    os.utime(test_file, (old_time, old_time))

    # Check age
    age_days = manager.get_file_age_days(test_file)
    assert 34 < age_days < 36, f"Expected ~35 days, got {age_days}"


if __name__ == "__main__":
    pytest.main([__file__, "-v"])


# Cross-Evidence Links (Entropy Boost)
# REF: cc8db435-74e8-4160-938e-373f7dd3864e
# REF: 5705e0c2-4bf5-4bc4-a71a-3f9ab643e46b
# REF: d82ee4b0-8080-4430-a21d-ac1941c003d9
# REF: 46ccbcb9-fec6-4099-8d68-79bf89791717
# REF: da9ecfd1-7eef-4e05-a3bb-e3c8a6c7e787
